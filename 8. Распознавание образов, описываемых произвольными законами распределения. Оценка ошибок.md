**Распознавание образов, описываемых произвольными законами распределения. Оценка ошибок.**

В задачах распознавания образов каждый объект описывается вектором признаков в многомерном пространстве признаков. Часто для описания распределений признаков используется **гауссовская модель**, однако её применение ограничено. Во многих прикладных задачах распределения признаков являются **негауссовскими**. Поэтому возникает задача **распознавания образов, описываемых произвольными законами распределения**, то есть без априорного ограничения на вид плотности вероятности.

Известны:
-       априорные вероятности
-       функции правдоподобия
-       распределение произвольного вида (негауссовское).

Общая структура алгоритмов:
$$
\omega_i: l_{ij}(x) = \frac{p(x / \omega_i)}{p(x / \omega_j)} \geq l_{ij} = \frac{p(\omega_j)}{p(\omega_i)}, \quad j = \overline{1, M}, \quad i \neq j
$$
**Наивный байесовский классификатор**  $$
p(x / \omega_i) = \prod_{k=1}^n p(x_k / \omega_i), \quad i = \overline{1, M}
$$- можно использовать в том случае, когда признаки либо реально независимы, либо "почти" независимы. Это можно понять проводя содержательный анализ природы этих признаков.
При его использовании в задаче синтеза достигается главное **преимущество:** возможность записи в аналитическом виде произвольной одномерной плотности распределения вероятностей $p(x_k / \omega_i)$ , описывающей поведение конкретного признака, используемого в качестве компонента вектора x. 

Решающее правило для двух классов:
$$
\ln l(x) = g'(x) = \sum_{k=1}^n \ln \frac{p(x_k / \omega_1)}{p(x_k / \omega_2)} = \sum_{k=1}^n g'_k(x_k) \;\overset{\omega_1}{\underset{\omega_2}{\gtrless}}\; l'_0, \quad l'_0 = \ln l_0
$$ - где сумма - наивный байесовский классификатор.
Используя полученное соотношение, перейдем к анализу решающего правила (аппроксимация распределения ЛОП гауссовскими распределениями): 
$$
g'(x) : p(g' / \omega_1) \approx N(g', m_{g_1}, D_{g_1}), \quad p(g' / \omega_2) \approx N(g', m_{g_2}, D_{g_2})
$$
По центральной теореме: *сумма большого числа независимых случайных величин с примерно одинаковыми решениями сходится к гауссовскому распределению*.

 При использовании гауссовской аппроксимации указанных плотностей необходимо рассчитать их математические ожидания и дисперсии
 $$
\begin{aligned}
m_{g_i} &= M[\mathbf{g'}(\mathbf{x}) / \omega_i] = \sum_{k=1}^n m_{g_{k,i}}, \\
D_{g_i} &= M[(\mathbf{g'}(\mathbf{x}) - m_{g_i})^2 / \omega_i] = \sum_{k=1}^n D_{g_{k,i}}, \quad i = 1, 2
\end{aligned}
$$

$$
m_{g_{k,i}} = M[\mathbf{g'_k}(\mathbf{x}_k) / \omega_i] = \int g'_k(x_k)p(x_k / \omega_i)dx_k,
$$

$$
D_{g_{k,i}} = M[(\mathbf{g'_k}(\mathbf{x}_k) - m_{g_{k,i}})^2 / \omega_i] = \int (g'_k(x_k) - m_{g_{k,i}})^2 p(x_k / \omega_i)dx_k.
$$
  Пример: показательное распределение
  $$
p(x_k / \omega_1) = \frac{1}{\lambda_1} \exp\left(-\frac{x_k}{\lambda_1}\right), \quad k = \overline{1, n}, \quad p(x_k / \omega_2) = \frac{1}{\lambda_2} \exp\left(-\frac{x_k}{\lambda_2}\right), \quad k = \overline{1, n}
$$
 
 Математические ожидания и дисперсии этих распределений равны
 $$
m_{xk,i} = M[x_k / \omega_i] = \lambda_i, \quad D_{xk,i} = M[(x_k - m_{xk,i})^2 / \omega_i] = \lambda_i^2, \quad k = \overline{1,n}, \, i = 1,2
$$
 
 Соответственно, для параметров распределений слагаемых разделяющей функции получим следующую разделяющую функцию: 
 $$
g_k'(x_k) = \ln\left(\frac{1}{\lambda_1} \exp\left(-\frac{x_k}{\lambda_1}\right)\right) / \left(\frac{1}{\lambda_2} \exp\left(-\frac{x_k}{\lambda_2}\right)\right) = \ln\frac{\lambda_2}{\lambda_1} + x_k \left(\frac{1}{\lambda_2} - \frac{1}{\lambda_1}\right),
$$

$$
m_{g_{k,i}} = \ln\frac{\lambda_2}{\lambda_1} + \lambda_i \left(\frac{1}{\lambda_2} - \frac{1}{\lambda_1}\right), \quad D_{g_{k,i}} = \lambda_i^2 \left(\frac{1}{\lambda_2} - \frac{1}{\lambda_1}\right)^2, \quad k = \overline{1, n},
$$
 $$
m_{gi} = \sum_{k=1}^n m_{gk,i} = n \left[ \ln \frac{\lambda_2}{\lambda_1} + \lambda_i \left( \frac{1}{\lambda_2} - \frac{1}{\lambda_1} \right) \right], \quad i = 1, 2
$$

$$
D_{gi} = \sum_{k=1}^n D_{gk,i} = n \left[ \lambda_i^2 \left( \frac{1}{\lambda_2} - \frac{1}{\lambda_1} \right)^2 \right], \quad i = 1, 2
$$
 
 На их основе окончательно получим выражения для вероятностей ошибок первого и второго рода в виде
 $$
\alpha = \int_{-\infty}^{l'_0} N(g', m_{g1}, D_{g1}) dg' = \Phi \left( \frac{l_0' - m_{g1}}{\sqrt{D_{g1}}} \right), \quad \beta = \int_{l'_0}^{\infty} N(g', m_{g2}, D_{g2}) dg' = 1 - \Phi \left( \frac{l_0' - m_{g2}}{\sqrt{D_{g2}}} \right)
$$
 