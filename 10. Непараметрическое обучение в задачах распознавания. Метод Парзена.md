
![[11. Непараметрическое обучение в задачах распознавания. Метод k-ближайших соседей#Непараметрическое обучение]]

# Метод Парзена(Метод ядерных оценок)

Суть метода заключается в том, что плотность в точке $x$ оценивается по количеству наблюдений из обучающей выборки, попавших в некоторую окрестность этой точки.
Формула для одномерного случая:

$$\tilde p(x) = \frac{1}{Nh}\sum_{i=1}^N\phi \left(\frac{x-x^{(i)}}{h} \right)$$

Здесь:
- $N$ - объём обучающей выборки.
- $h$ - коэффициент сглаживания (ширина окна)
- $\phi(\cdot)$ - ядро (оконная функция)

## Роль ядра и коэффициента $h$

Ядро $\phi$ определяет форму вклада каждой точки выборки в итоговую оценку. 

Виды:
- Прямоугольная:

$$\phi(u/h) = \begin{cases} 1, & |u/h| \le 1/2 \\ 0, & |u/h| > 1/2 \end{cases}$$

- Треугольная
  
  $$\frac{1}{h}\phi(\frac{u}{h}) = \begin{cases} \frac{1}{h}(1-|u/h|), & |u/h| \le 1 \\ 0, & |u/h| > 1 \end{cases}$$
  
- Гауссовская
  
  $$\frac{1}{h}\phi(\frac{u}{h}) = \frac{1}{\sqrt{2\pi h}}\exp \left(-\frac{u^2}{2h^2}\right)$$
  
- Показательная
  
  $$\frac{1}{h}\phi(\frac{u}{h}) = \frac{1}{2 h}\exp \left(-\left|\frac{u}{h}\right|\right)$$
  
Ширина окна $h$ влияет на ширину промежутка к которому мы применяем функцию. При слишком малом $h$ оценка слишком сильно подстраивается под конкретные точки обучающей выборки (переобучается). При слишком большом $h$ оценка становится слишком грубой и не отражает реальных особенностей распределения.

## Решающее правило

Поскольку метод Парзена даёт нам оценку плотности $\tilde p(x|\omega_i)$ для каждого класса $\omega_i$, мы можем использовать подстановочный алгоритм. Мы заменяем истинные плотности в формуле Байеса на их непараметрические оценки.
Для двух классов правило будет выглядеть так:

$$x \in \omega_1, \text{если }\tilde p(x|\omega_1)P(\omega_1) > \tilde p(x|\omega_2,)P(\omega_2)$$