### Кластеризация образов.
> Разбиение множества объектов на кластеры по общим признакам
> Без учителя 

**Кластер** - группа однотипных объектов, расположенных недалеко друг от друга в пространстве признаков.

---
### Критерии эффективности.  Детерменисткий подход.

*Задача кластеризации:*
Смешанная обучающая выборка образов $X^N = \{ x^{(1)},...,x^{(N)} \}, \ x^*\in R^n,$ принадлежит **M**(может быть известно и не известно),
Заданы функции расстояния $d( x^{(i)},x^{(j)})$(степень сходства образов)

*Задача:*
В соответствии с критерием оптимальности выполнить разбиение смешанной выборки образов $Q_M=\{X^{N_1},...,X^{N_M}\}$ на группы $X^{N_i} = \{ x^{(1,i)},...,x^{(N_i,i)} \},i=\overline{1,M}$, со свойствами: $X^{N_i} \neq \emptyset, i=\overline{1,M}$;    $\bigcup_{i=1}^{M} X^{N_i} = X^N$;    $\bigcap_{i=1}^{M} X^{N_i} = \emptyset$

%%При неизвестном М единый критерий оптимальности отсутствует и задача не корректна, но может быть решена%%
**Критерии эффективности:**
1. Среднее суммы квадратов расстояния образов каждого кластера до его центра –***внутриклассовый разброс (ВР)***$$E_W ( X^N, Q_M ) = \sum_{i=1}^{M} \sum_{k=1}^{N_i} d( x^{(k,i)}, m_i )^2, \quad m_i = \frac{1}{N_i} \sum_{k=1}^{N_i} x^{(k,i)}, \quad i = \overline{1, M}$$ Для евклидова расстояния - через матрицы рассеяния классов$$E_W ( X^N, Q_M ) = \text{tr} S_W = \text{tr} \left( \sum_{i=1}^{M} S_i \right), \ S_i = \sum_{k=1}^{N_i} ( x^{(k,i)} - m_i )( x^{(k,i)} - m_i )^T$$  $E_W ( X^N, Q_M ) \to \min$ (группирование с минимальной дисперсией) для известного М,
  %%при неизвестном - монотонное уменьшение числа кластеров  с увеличением М => не имеет смысла%%
2. Средняя сумма квадратов расстояний между центрами кластеров относительно общего центра -  ***межклассовый разброс (MР)*** $$E_B ( X^N, Q_M ) = \sum_{i=1}^{M} N_i d( m_i, m )^2, \quad m = \frac{1}{N} \sum_{k=1}^{N} x^{(k)} = \frac{1}{N} \sum_{i=1}^{M} N_i m_i$$ Для евклидова расстояния - через матрицу рассеяния  между классами $$E_B ( X^N, Q_M ) = \text{tr} S_B, \quad S_B = \sum_{i=1}^{M} N_i (m_i - m)( m_i - m )^T$$  $E_B ( X^N, Q_M ) \to \max$ 
3. **Общая матрица рассеяния**(не зависит от разбиения):$S_T = S_W + S_B = const$
----
### Иерархическая кластеризация
> Последовательное объединение(разбиение) групп образов по правилам слияния до М групп.
> Объединение - **агломеративная кластеризация**, при разбиении – **дивизимная.**

На каждом шаге две группы объединяются(агломеративная)
При реализации строят полное дерево вложений - дендрограмму.

**Алгоритм агломеративной кластеризации:**
1. $\tilde{M} = N$, Начальное разбиение $Q_N^1 = \{ X^1, \dots, X^N \}, \quad X^j = x^{(j)}$ 
2. Для выполнения разбиения $Q^k_{N-k+1}$  и $\tilde{M} = N-k+1$ с использованием заданной функции растояния находится  ближайшая пара групп $\min_{i, j} D(X^{N_i}, X^{N_j})$
3. Слияние выбранных групп $X^{N_i + N_j} = X^{N_i} \cup X^{N_j}, \quad \tilde{M} = N - k$
4. Если $\tilde{M} = M$ [остановка]

**Функции расстояния:**
- между ближайшими соседями $D_{NN}(X^{N_i}, X^{N_j}) = \min_{k, s} d(x^{(k,i)}, x^{(s,j)})$
- между самыми удаленными соседями $D_{FN}(X^{N_i}, X^{N_j}) = \max_{k, s} d(x^{(k,i)}, x^{(s,j)})$
- среднее расстояние $D_{BG}(X^{N_i}, X^{N_j}) = \frac{1}{N_i N_j} \sum_{k=1}^{N_i} \sum_{s=1}^{N_j} d(x^{(k,i)}, x^{(s,j)})$
- расстояние между центрами кластеров $D_{BC}(X^{N_i}, X^{N_j}) = d^2(m_i, m_j)$ $m_i = \frac{1}{N_i} \sum_{k=1}^{N_i} x^{(k,i)}, \quad m_j = \frac{1}{N_j} \sum_{s=1}^{N_j} x^{(s,j)}$ 
- расстояние Уорда $D_{WM}(X^{N_i}, X^{N_j}) = \frac{N_i N_j}{N_i + N_j} d^2(m_i, m_j)$