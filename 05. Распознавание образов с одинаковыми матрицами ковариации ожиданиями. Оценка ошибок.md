# Линейное решающее правило

когда матрицы ковариации классов одинаковы ($C_1 = C_2 = C$), логарифм отношения правдоподобия (ЛОП) становится линейной функцией вектора признаков $x$.
Уравнение разделяющей границы для двух классов в этом случае представляет собой гиперплоскость. Выражение для ЛОП $g'(x)$ выглядит так:

$$g'(x) = x^T C^{-1} (m_1 - m_2) - \frac{1}{2} (m_1 + m_2)^T C^{-1} (m_1 - m_2)$$

где $m_1, m_2$ — математические ожидания классов.

## Оценка вероятностей ошибок

Поскольку ЛОП здесь - это линейная комбинация гауссовских величин, сама функция $g'(x)$ также распределена по гауссовскому закону. Это позволяет нам аналитически расчитать вероятности ошибок первого ($\alpha$) и второго ($\beta$) рода
- **Математические ожидания** ЛОП для двух гипотез симметричны: $m_{g1} = h$ и $m_{g2} = -h$
- **Дисперсии** одинаковы: $D_{g1} = D_{g2} = 2h$.
- **Параметр $h$** определяется как: $h = \frac{1}{2} (m_1 - m_2)^T C^{-1} (m_1 - m_2)$.
Если априорные вероятности классов равны ($p(\omega_1) = p(\omega_2)$), то порог $l'_0 = 0$, и вероятности ошибок становятся одинаковыми:

$$\alpha = \beta = \Phi\left(-\frac{1}{2} \sqrt{(m_1 - m_2)^T C^{-1} (m_1 - m_2)}\right)$$

Величина под корнем — это квадрат расстояния Махаланобиса между центрами классов. Таким образом, качество распознавания напрямую зависит от этого расстояния.

# Многоклассовое распознавание 

Когда нам нужно распределить объекты по $M$ классам, мы используем набор разделяющих функций $g_i'(x)$, где $i = 1, \dots, M$. В случае одинаковых матриц ковариации ($C_i = C$) эти функции остаются **линейными** относительно признаков $x$.

Правило решения формулируется просто: объект относится к классу $\omega_i$, если его разделяющая функция в этой точке максимальна:

$$\omega_i: g_i'(x) \ge g_j'(x) \text{ для всех } j \ne i$$

Сами функции принимают вид:

$$g_i'(x) = x^T C^{-1} m_i - \frac{1}{2} m_i^T C^{-1} m_i + \ln(p(\omega_i))$$

Границы между областями в многомерном пространстве представляют собой фрагменты гиперплоскостей. Каждая такая грань — это результат попарного сравнения двух классов.

## Оценка вероятности ошибок для многоклассового распознавания

Для многоклассового случая рассчитать точную вероятность ошибки гораздо сложнее, чем для двух классов. Поэтому часто используют **нижнюю границу** вероятности правильного распознавания $P_c^{(i)}$ через вероятности попарных ошибок $p_{ij}$:

$$P_c^{(i)} \ge 1 - \sum_{j=1, j \ne i}^{M} p_{ij}$$

Где $p_{ij}$ — это вероятность того, что объект класса $i$ будет принят за класс $j$ при их попарном сравнении.