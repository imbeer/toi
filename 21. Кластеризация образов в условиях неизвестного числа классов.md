Самая сложная среди задач кластерного анализа. Основной подход – подбор числа кластеров $\tilde M$.

# Критерии оптимальности

Для подбора необходим *критерий (индекс) оптимальности кластеризации:*

## 1. Критерий Калинского – Харабаша

   Основан на максимизации *отношения показателей МР^[межклассовый разброс] и ВР^[внутриклассовый разброс]* при переборе нескольких кластеризаций.
   
   $$I_{CH}(\tilde M) = \frac {E_B(X^N,Q_{\tilde M})(N-\tilde M)} {E_W(X^N,Q_{\tilde M})(\tilde M - 1)}$$
   
## 2. Критерий Хржановского – Лаи

   Основан на выявлении *максимального скачка ВР* при последовательном изменении числа классов.
   
   $$I_{CL}(\tilde M) = \left| \frac{\Delta E_W(\tilde M)}{\Delta E_W(\tilde M + 1)} \right|,$$
   
   $$\Delta E_W(\tilde M) = (\tilde M-1)^{1/n} E_W(X^N,Q_{\tilde M - 1})-\tilde M^{1/n} E_W(X^N,Q_{\tilde M}).$$
   
## 3. Критерий Дэвиса – Болдуина

   При его вычислении определяют среднюю схожесть между каждым кластером и наиболее близким ему кластером.
   
   $$I_{DB}(\tilde M) = \frac 1 {\tilde M} \sum_{i=1}^{\tilde M} R_i,$$
   
   $$R_i = \max_j R_{ij},\ R_{ij} = \frac {e_{wi} + e_{wj}} {h_{ij}},$$
   
   $$e_{wi} = \left[ \frac 1 N_i \sum_{k=1}^{N_i} \left|\left| x^{(k,i) - m_i} \right|\right|^p \right]^{1/p},$$
   
   $$h_{ij} = \left[ \sum_{k=1}^{n} \left| m_{i,k} - m_{j,k} \right|^q \right]^{1/q}.$$
   
   Здесь $R_{ij}$ – мера схожести двух классов.

## 4. Индекс GAP

   Основан на анализе статистики расхождений (*англ.* gap – "промежуток") между вычисленным значением ВР и усреднёнными значениями этой же величины, полученными при кластеризации унифицированных выборок, сгенерированных методом Монте-Карло на основе некоторого стандартного распределения.
   
   > [!info] Особенность
   > Индекс GAP можно вычислить даже в случае одного кластера.
   
   $$I_{GAP}(\tilde M) = \frac 1 B \sum_{k=1}^B \log E^*_W(X^N,Q_{\tilde M}) - \log E_W(X^N,Q_{\tilde M}).$$
   
## 5. Индекс оценки силуэта

Основан на вычислении величины «силуэта» для каждого образа, который определяет, насколько этот образ схож с образами собственного кластера, и, как он отличается от образов других кластеров.

Суммарный силуэт:

$$I_{SV} = \frac 1 N \sum_{i=1}^{\tilde M} \sum_{k=1}^{N_i} r_{i,k} = \frac {b_{i,k}-a_{i,k}} {\max(b_{i,k},a_{i,k})},$$

где

$$a_{i,k} = \frac 1 {N_1-1} \sum_{s=1}^{N_i} d(x^{(k,i)},x^{(k,s)}),$$

$$b_{i,k} = \min_j \left[ \frac 1 {N_j} \sum_{t=1}^{N_j} d(x^{(k,i)},x^{(t,j)}) \right].$$

Здесь $r_{i,k}$ – индекс силуэта для образа $x^{(k,i)} \in X^{N_j}$.

# Общий вывод

Задача кластерного анализа при неизвестном числе классов имеет неоднозначное решение с точки зрения выбора используемых алгоритмов и рекомендаций по их настройкам.

Решить её можно только в ходе проведения масштабных и многофакторных модельных экспериментов, выполняемых для "пилотных" вариантов алгоритмов, с применением для этих целей современных инструментальных средств компьютерного моделирования.

На качество и возможности практического применения влияют следующие характеристики:

- *точность алгоритма* анализа данных (измеряемый уровень допущенных ошибок)
- *вычислительная сложность* и быстродействие
- устойчивость по отношению к *аномальным наблюдениям
- способность к *обобщению* (сохранению уровня ошибок на неизвестных данных)
- *сложность настройки* параметров алгоритма
- *наличие библиотек* с его реализацией